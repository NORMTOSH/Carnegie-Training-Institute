{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingRegressor, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px \n",
    "import plotly.graph_objects as go\n",
    "import scipy.stats as stats\n",
    "\n",
    "import mplcyberpunk\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"always\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid', font_scale=1.4)\n",
    "plt.style.use(\"cyberpunk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Basic Data Cleaning and Feature Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>85 Turner St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>3/12/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/02/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>5 Charles St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>40 Federation La</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.7969</td>\n",
       "      <td>144.9969</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>55a Park St</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>VB</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>4/06/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8072</td>\n",
       "      <td>144.9941</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Suburb           Address  Rooms Type      Price Method SellerG  \\\n",
       "0  Abbotsford      85 Turner St      2    h  1480000.0      S  Biggin   \n",
       "1  Abbotsford   25 Bloomburg St      2    h  1035000.0      S  Biggin   \n",
       "2  Abbotsford      5 Charles St      3    h  1465000.0     SP  Biggin   \n",
       "3  Abbotsford  40 Federation La      3    h   850000.0     PI  Biggin   \n",
       "4  Abbotsford       55a Park St      4    h  1600000.0     VB  Nelson   \n",
       "\n",
       "        Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n",
       "0  3/12/2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n",
       "1  4/02/2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n",
       "2  4/03/2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n",
       "3  4/03/2017       2.5    3067.0  ...       2.0  1.0      94.0           NaN   \n",
       "4  4/06/2016       2.5    3067.0  ...       1.0  2.0     120.0         142.0   \n",
       "\n",
       "   YearBuilt  CouncilArea Lattitude  Longtitude             Regionname  \\\n",
       "0        NaN        Yarra  -37.7996    144.9984  Northern Metropolitan   \n",
       "1     1900.0        Yarra  -37.8079    144.9934  Northern Metropolitan   \n",
       "2     1900.0        Yarra  -37.8093    144.9944  Northern Metropolitan   \n",
       "3        NaN        Yarra  -37.7969    144.9969  Northern Metropolitan   \n",
       "4     2014.0        Yarra  -37.8072    144.9941  Northern Metropolitan   \n",
       "\n",
       "  Propertycount  \n",
       "0        4019.0  \n",
       "1        4019.0  \n",
       "2        4019.0  \n",
       "3        4019.0  \n",
       "4        4019.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "\n",
    "data = \"melb_data.csv\"\n",
    "df=pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13580 entries, 0 to 13579\n",
      "Data columns (total 21 columns):\n",
      "Suburb           13580 non-null object\n",
      "Address          13580 non-null object\n",
      "Rooms            13580 non-null int64\n",
      "Type             13580 non-null object\n",
      "Price            13580 non-null float64\n",
      "Method           13580 non-null object\n",
      "SellerG          13580 non-null object\n",
      "Date             13580 non-null object\n",
      "Distance         13580 non-null float64\n",
      "Postcode         13580 non-null float64\n",
      "Bedroom2         13580 non-null float64\n",
      "Bathroom         13580 non-null float64\n",
      "Car              13518 non-null float64\n",
      "Landsize         13580 non-null float64\n",
      "BuildingArea     7130 non-null float64\n",
      "YearBuilt        8205 non-null float64\n",
      "CouncilArea      12211 non-null object\n",
      "Lattitude        13580 non-null float64\n",
      "Longtitude       13580 non-null float64\n",
      "Regionname       13580 non-null object\n",
      "Propertycount    13580 non-null float64\n",
      "dtypes: float64(12), int64(1), object(8)\n",
      "memory usage: 2.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Summary information of the data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Descriptive Summary\n",
    "The `df.describe()` function provides summary statistics that can be used for various operations and analysis. Here are some common operations that can be performed using the information obtained from `df.describe()`:\n",
    "\n",
    "1. **Data Cleaning:** By examining the count of each column, you can identify missing values. If a column has a count less than the total number of rows in the DataFrame, you can decide how to handle those missing values, such as imputing them with appropriate values or removing rows or columns with missing data.\n",
    "\n",
    "2. **Data Exploration:** Descriptive statistics like mean, standard deviation, minimum, and maximum can give you insights into the distribution and variability of the data. You can identify the range of values, detect potential outliers, and understand the spread of data in each column. This information can help you explore and understand the characteristics of your dataset.\n",
    "\n",
    "3. **Data Validation:** Summary statistics can be used to validate the data and check for any anomalies or inconsistencies. For example, if you have domain knowledge or expectations about the data, you can compare the minimum and maximum values to ensure they fall within the expected range. If any values seem unreasonable, it may indicate errors in the data.\n",
    "\n",
    "4. **Feature Engineering:** Summary statistics can guide feature engineering decisions. For instance, if you observe a large difference between the mean and maximum values in a column, it suggests the presence of outliers. You can then consider applying transformations or creating new features to handle these outliers or capture the skewed distribution of the data.\n",
    "\n",
    "5. **Data Visualization:** Summary statistics provide a high-level understanding of the data, and they can be used to create visualizations. Box plots, histograms, or bar charts based on the quartiles, mean, and standard deviation can help visualize the distribution and variability of the data. These visualizations can aid in communicating insights and patterns effectively.\n",
    "\n",
    "6. **Modeling Decisions:** Descriptive statistics provide important insights for modeling decisions. For instance, understanding the range and distribution of the target variable can help determine the appropriate modeling approach, such as classification or regression. Additionally, identifying potential outliers or highly variable features can guide decisions on data preprocessing techniques or feature selection methods.\n",
    "\n",
    "Overall, the summary statistics obtained from `df.describe()` serve as a starting point for various data operations, including data cleaning, exploration, validation, feature engineering, visualization, and modeling decisions. They provide valuable information for understanding and manipulating the data to achieve the desired analytical goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Price</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.7969</td>\n",
       "      <td>144.9969</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>-37.8072</td>\n",
       "      <td>144.9941</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rooms      Price  Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  \\\n",
       "0      2  1480000.0       2.5    3067.0       2.0       1.0  1.0     202.0   \n",
       "1      2  1035000.0       2.5    3067.0       2.0       1.0  0.0     156.0   \n",
       "2      3  1465000.0       2.5    3067.0       3.0       2.0  0.0     134.0   \n",
       "3      3   850000.0       2.5    3067.0       3.0       2.0  1.0      94.0   \n",
       "4      4  1600000.0       2.5    3067.0       3.0       1.0  2.0     120.0   \n",
       "\n",
       "   BuildingArea  YearBuilt  Lattitude  Longtitude  Propertycount  \n",
       "0           NaN        NaN   -37.7996    144.9984         4019.0  \n",
       "1          79.0     1900.0   -37.8079    144.9934         4019.0  \n",
       "2         150.0     1900.0   -37.8093    144.9944         4019.0  \n",
       "3           NaN        NaN   -37.7969    144.9969         4019.0  \n",
       "4         142.0     2014.0   -37.8072    144.9941         4019.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numeric features from the dataset\n",
    "numeric_feat=df.select_dtypes(include=[np.number])\n",
    "numeric_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for Numeric features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features from the dataset\n",
    "cat_feat=df.select_dtypes(include=[object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for Categorical features\n",
    "df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key**\n",
    "\n",
    "Interpreting the information provided by `df.describe()` involves understanding the statistics generated for each column of the DataFrame. Here's a guide on how to interpret the information:\n",
    "\n",
    "1. **Count:** The count tells you the number of non-missing values in each column. If the count is less than the total number of rows in the DataFrame, it indicates the presence of missing values.\n",
    "\n",
    "2. **Mean:** The mean represents the average value of the data in each column. It gives you an idea of the central tendency of the data. For example, if the mean of a column is 50, it suggests that the average value in that column is around 50.\n",
    "\n",
    "3. **Standard Deviation:** The standard deviation measures the spread or dispersion of the data around the mean. A higher standard deviation indicates that the data points are more spread out, while a lower standard deviation suggests that the data points are closer to the mean. It helps understand the variability within the column.\n",
    "\n",
    "4. **Minimum and Maximum:** The minimum and maximum values provide the range of values present in each column. The minimum value is the smallest value, while the maximum value is the largest value. They help identify the lower and upper bounds of the data.\n",
    "\n",
    "5. **Quartiles (25th, 50th, 75th percentiles):** Quartiles divide the data into four equal parts, providing insights into the distribution of the data. The 25th percentile (Q1) represents the value below which 25% of the data falls, the 50th percentile (Q2) is the median or middle value, and the 75th percentile (Q3) indicates the value below which 75% of the data falls. Quartiles help understand the spread of data and identify potential outliers.\n",
    "\n",
    "By examining these statistics, you can gain insights into the central tendency, variability, range, and distribution of the data in each column. It helps you understand the characteristics of the dataset and make informed decisions regarding data cleaning, feature engineering, and modeling approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research:**\n",
    "What the insights are gathered here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total amount of null values on column/feature\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage null values\n",
    "(df.isnull().sum() / len(df)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research:**\n",
    "\n",
    "The Car, BuildingArea, YearBuilt and CouncilArea have null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Exploratory Data Analysis (EDA)\n",
    "\n",
    "Exploratory Data Analysis (EDA) graphs are visualizations used to gain insights into the underlying patterns, distributions, relationships, and anomalies within a dataset. They play a crucial role in the data analysis process and provide several key benefits:\n",
    "\n",
    "1. **Data Understanding:** EDA graphs help in understanding the structure and characteristics of the data. They allow you to observe the data's shape, spread, and central tendency, providing a visual representation of the data distribution. This understanding is essential for making informed decisions and formulating appropriate analysis strategies.\n",
    "\n",
    "2. **Pattern Identification:** EDA graphs reveal patterns and trends within the data. By visualizing the data, you can identify recurring patterns, cycles, or seasonality. This information can help in detecting dependencies, correlations, or underlying relationships that might not be apparent from raw data.\n",
    "\n",
    "3. **Outlier Detection:** Outliers are data points that significantly deviate from the rest of the data. EDA graphs, such as box plots or scatter plots, can highlight these anomalies. Outliers may indicate errors, data quality issues, or rare events that need to be investigated further.\n",
    "\n",
    "4. **Data Distribution:** Histograms and density plots provide insights into the distribution of a variable. They help identify whether the data follows a normal distribution or if it is skewed or multimodal. Understanding the data distribution can guide decisions related to modeling assumptions and appropriate statistical techniques.\n",
    "\n",
    "5. **Feature Selection:** EDA graphs can assist in feature selection by visualizing the relationships between variables. Scatter plots and correlation matrices can reveal correlations or dependencies among variables. This information aids in identifying important features for modeling or feature engineering.\n",
    "\n",
    "6. **Data Imbalance:** In classification problems, EDA graphs can expose class imbalances, where the number of observations in different classes is significantly different. Imbalanced data can lead to biased models, and EDA graphs can help identify the need for data resampling techniques or alternative modeling approaches.\n",
    "\n",
    "7. **Visualization of Time Series Data:** Time series plots can show how a variable changes over time. EDA graphs can reveal trends, seasonal patterns, or unusual behavior in time-dependent data. These insights are valuable for forecasting, anomaly detection, and decision-making in various domains.\n",
    "\n",
    "8. **Communication and Reporting:** EDA graphs are effective tools for communicating findings and insights to stakeholders or team members. Visual representations of data are often easier to interpret and understand than raw numbers or statistical measures. EDA graphs enable clear and concise communication of complex data patterns.\n",
    "\n",
    "Overall, EDA graphs provide a visual framework for exploring and understanding the data. They complement statistical analyses, uncover hidden patterns, identify outliers, guide modeling decisions, and facilitate effective communication of insights. EDA graphs are an integral part of the exploratory data analysis process and contribute significantly to the overall data analysis workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When analyzing a dataset with the given columns, you can ask various questions to gain insights and understand the properties in the dataset. Here are some potential questions you can explore:\n",
    "\n",
    "1. **What is the distribution of property prices?**\n",
    "   - Analyze the `Price` column to understand the range, mean, median, and spread of property prices.\n",
    "   - Identify any outliers or unusual patterns in the price distribution.\n",
    "\n",
    "2. **How does the number of rooms (`Rooms`) relate to property prices (`Price`)?**\n",
    "   - Explore the relationship between the number of rooms and the property prices.\n",
    "   - Determine if there is a positive correlation between the two variables.\n",
    "\n",
    "3. **What are the different types of properties (`Type`) in the dataset?**\n",
    "   - Identify the unique property types and their respective frequencies.\n",
    "   - Analyze how the property type affects the prices and other attributes.\n",
    "\n",
    "4. **Which suburbs (`Suburb`) have the highest property prices?**\n",
    "   - Determine the suburbs with the most expensive properties.\n",
    "   - Visualize the distribution of property prices across different suburbs.\n",
    "\n",
    "5. **Are there any temporal trends in property prices (`Price`) over time (`Date`)?**\n",
    "   - Analyze how property prices change over different dates or time periods.\n",
    "   - Identify any seasonal or long-term trends in the data.\n",
    "\n",
    "6. **What is the average land size (`Landsize`) and building area (`BuildingArea`) for different property types?**\n",
    "   - Compare the average land size and building area among different property types.\n",
    "   - Identify any variations or trends in the sizes of properties.\n",
    "\n",
    "7. **Is there a relationship between property attributes, such as the number of bedrooms (`Bedroom2`), bathrooms (`Bathroom`), and car spaces (`Car`)?**\n",
    "   - Investigate how the number of bedrooms, bathrooms, and car spaces are related.\n",
    "   - Determine if certain combinations of these attributes are more common.\n",
    "\n",
    "8. **Which council areas (`CouncilArea`) have the highest number of properties (`Propertycount`)?**\n",
    "   - Identify the council areas with the highest property counts.\n",
    "   - Analyze if property counts correlate with other factors such as location or property prices.\n",
    "\n",
    "9. **Are there any spatial patterns in property locations (`Lattitude`, `Longtitude`) and prices (`Price`)?**\n",
    "   - Visualize the property locations on a map using latitude and longitude coordinates.\n",
    "   - Explore if there are any spatial patterns or clusters in property prices.\n",
    "\n",
    "10. **How does the distance to a particular location (`Distance`) affect property prices (`Price`)?**\n",
    "    - Analyze the relationship between the distance to a specific location and property prices.\n",
    "    - Determine if there is a correlation or any notable patterns.\n",
    "\n",
    "These are just a few examples of the questions you can ask during your analysis. Depending on your specific goals and interests, you can further refine these questions or explore additional aspects of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the distribution of property prices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Histogram:**\n",
    "   - Identifies the distribution of a variable, including its shape (symmetric, skewed, bimodal, etc.).\n",
    "   - Reveals the central tendency and spread of the data.\n",
    "   - Highlights the presence of outliers or unusual patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in df.columns:\n",
    "    #sns.histplot(df[i],kde=True,color=\"y\")\n",
    "    #plt.title(\"Distribution of \"+i)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure size\n",
    "plt.figure(figsize=(20,7))\n",
    "\n",
    "sns.histplot(df['Price'],kde=True,color=\"y\")\n",
    "plt.title(\"Distribution of Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Research:**\n",
    "\n",
    "The Price is **Right skewed**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Box Plot:**\n",
    "   - Identifies the distribution of a variable, including the median, quartiles, and outliers.\n",
    "   - Highlights potential outliers in the data.\n",
    "   - Helps in comparing the distributions of different variables or groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    if i in numeric_feat:\n",
    "        plt.figure(figsize=(20,7))\n",
    "        fig=px.box(df, y=[i])\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers=['Rooms', 'Price', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude', 'Propertycount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:**\n",
    "\n",
    "All the numeric features:- Rooms, Price, Distance, Postcode, Bedroom2, Bathroom, Car, Landsize, BuildingArea, YearBuilt, Lattitude, Longtitude and Propertycount, have outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the number of rooms (Rooms) relate to property prices (Price)?\n",
    "\n",
    "**Scatter Plot:**\n",
    "   - Identifies the relationship and correlation between two variables.\n",
    "   - Reveals patterns, trends, or clusters in the data.\n",
    "   - Highlights potential outliers or anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "sns.scatterplot(x=df[\"Rooms\"],y=df[\"Price\"])\n",
    "plt.title(\"Rooms vs Price Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there a relationship between property attributes, such as the number of bedrooms (Bedroom2), bathrooms (Bathroom), and car spaces (Car)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the relevant columns for analysis\n",
    "attributes = ['Bedroom2', 'Bathroom', 'Car']\n",
    "property_data = df[attributes]\n",
    "\n",
    "# Create a scatter matrix plot\n",
    "sns.pairplot(property_data)\n",
    "plt.show()\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = property_data.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there any spatial patterns in property locations (Lattitude, Longtitude) and prices (Price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of property locations and prices\n",
    "scatter_fig = px.scatter(df, x='Longtitude', y='Lattitude', color='Price')\n",
    "scatter_fig.update_layout(title='Property Locations and Prices',\n",
    "                          xaxis_title='Longitude', yaxis_title='Latitude')\n",
    "scatter_fig.show()\n",
    "\n",
    "# Spatial heatmap of property prices\n",
    "heatmap_fig = px.density_mapbox(df, lat='Lattitude', lon='Longtitude', z='Price',\n",
    "                                radius=10, center=dict(lat=-37.8136, lon=144.9631),\n",
    "                                zoom=10, mapbox_style='carto-positron')\n",
    "heatmap_fig.update_layout(title='Spatial Heatmap of Property Prices')\n",
    "heatmap_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the distance to a particular location (Distance) affect property prices (Price)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot or line plot of distance and property prices\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.scatter(df['Distance'], df['Price'])\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Distance vs. Property Prices')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the correlation coefficient\n",
    "correlation_coefficient = df['Distance'].corr(df['Price'])\n",
    "print('Correlation Coefficient:', correlation_coefficient)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are there any temporal trends in property prices (Price) over time (Date)?\n",
    "\n",
    "**Line Plot (Time Series):**\n",
    "\n",
    "- Identifies the trends and patterns over time.\n",
    "- Reveals seasonality or cyclic patterns in the data.\n",
    "- Helps in forecasting or detecting anomalies in time-dependent data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert 'Date' column to DateTime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Group the dataset by a specific time period, such as month, quarter, or year and calculate average property prices\n",
    "monthly_prices = df.groupby(df['Date'].dt.to_period('M'))['Price'].mean()\n",
    "\n",
    "# Plot the time series of property prices\n",
    "plt.figure(figsize=(20, 8))\n",
    "monthly_prices.plot()\n",
    "plt.xlabel('Date (Month)')\n",
    "plt.ylabel('Average Price')\n",
    "plt.title('Temporal Trends in Property Prices')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which suburbs (Suburb) have the highest property prices?\n",
    "\n",
    "**Bar Chart:**\n",
    "   - Identifies the comparison or distribution of categorical variables.\n",
    "   - Helps in understanding the frequency or count of each category.\n",
    "   - Highlights differences or similarities between categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group by Suburb and calculate average property prices\n",
    "suburb_prices = df.groupby('Suburb')['Price'].mean().nlargest(40)  # Adjust '10' to the desired number of suburbs to display\n",
    "\n",
    "# Plot the suburb prices\n",
    "plt.figure(figsize=(20, 8))\n",
    "suburb_prices.plot(kind='bar')\n",
    "plt.xlabel('Suburb')\n",
    "plt.ylabel('Average Price')\n",
    "plt.title('Suburbs with Highest Property Prices')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which council areas (Regionname) have the highest number of properties (Propertycount)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Council Area and count properties\n",
    "property_counts = df.groupby('Regionname')['Propertycount'].count().sort_values(ascending=False)\n",
    "\n",
    "# Plot the property counts\n",
    "plt.figure(figsize=(20, 8))\n",
    "property_counts.plot(kind='bar')\n",
    "plt.xlabel('Regionname')\n",
    "plt.ylabel('Property Count')\n",
    "plt.title('Number of Properties by Regionname')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which council areas (CouncilArea) have the highest number of properties (Propertycount)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Council Area and count properties\n",
    "property_counts = df.groupby('CouncilArea')['Propertycount'].count().sort_values(ascending=False)\n",
    "\n",
    "# Plot the property counts\n",
    "plt.figure(figsize=(20, 8))\n",
    "property_counts.plot(kind='bar')\n",
    "plt.xlabel('Council Area')\n",
    "plt.ylabel('Property Count')\n",
    "plt.title('Number of Properties by Council Area')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.scatterplot(y=df['Regionname'], x=df['CouncilArea'])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the different types of properties (Type) in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Create a bar chart\n",
    "ax_type=sns.countplot(df['Type'])\n",
    "for p in ax_type.patches:\n",
    "   ax_type.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "\n",
    "# Create a bar chart\n",
    "ax_type=sns.countplot(df['Method'])\n",
    "for p in ax_type.patches:\n",
    "   ax_type.annotate('{:.1f}'.format(p.get_height()), (p.get_x()+0.25, p.get_height()+0.01))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "\n",
    "# Create a bar chart\n",
    "sns.countplot(hue='Method', x='Type', data=df)\n",
    "plt.title(\"Method vs Type Distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the average land size (Landsize) and building area (BuildingArea) for different property types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Property Type and calculate average land size and building area\n",
    "average_sizes = df.groupby('Type')['Landsize', 'BuildingArea'].mean()\n",
    "\n",
    "# Plot the average land size and building area\n",
    "average_sizes.plot(kind='bar', figsize=(10, 6))\n",
    "plt.xlabel('Property Type')\n",
    "plt.ylabel('Average Size')\n",
    "plt.title('Average Land Size and Building Area by Property Type')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corelational Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Heatmap:**\n",
    "   - Identifies patterns and relationships between multiple variables.\n",
    "   - Reveals correlations or dependencies between variables.\n",
    "   - Highlights clusters or groups of variables with similar characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "corr = df.corr()\n",
    "fig = px.imshow(corr, text_auto=True, aspect=\"auto\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original=df\n",
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Dealing Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with Numeric features\n",
    "df.Car=df.Car.fillna(df.Car.median())\n",
    "df.BuildingArea=df.BuildingArea.fillna(df.BuildingArea.median())\n",
    "df.YearBuilt=df.YearBuilt.fillna(df.YearBuilt.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with categorical features\n",
    "df['CouncilArea']=df['CouncilArea'].fillna(df['CouncilArea'].value_counts().index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in outliers:\n",
    "    minimum,q1,middle,q3,maximum=np.quantile(df[i],[0,0.25,0.50,0.75,1])\n",
    "    IQR=q3-q1\n",
    "    lower_fence=q1-(IQR*1.5)\n",
    "    higher_fence=q3+(IQR*1.5)\n",
    "    print(\"In \"+i+\" Column any values beyond the Range \"+str(lower_fence)+\" and \"+str(higher_fence)+\" are outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:**\n",
    "\n",
    "The range of outliers is huge. Filtering them out won't be the suitable option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.get_dummies(df,columns=['Suburb', 'Type', 'Method', 'CouncilArea', 'Regionname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Categorical Columns to Numericals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Suburb\"]=encoder.fit_transform(df[[\"Suburb\"]])\n",
    "df[\"Type\"]=encoder.fit_transform(df[[\"Type\"]])\n",
    "df[\"Method\"]=encoder.fit_transform(df[[\"Method\"]])\n",
    "df[\"CouncilArea\"]=encoder.fit_transform(df[[\"CouncilArea\"]])\n",
    "df[\"Regionname\"]=encoder.fit_transform(df[[\"Regionname\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Address\",\"SellerG\",\"Date\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide Data into Independent and Dependent Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(\"Price\", axis=1)\n",
    "y=df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Independent Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "x_new=scaler.fit_transform(x)\n",
    "x=pd.DataFrame(x_new,columns=x.columns)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide data into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape,y_train.shape,x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model=LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred=model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the cost functions with respect to predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={}\n",
    "d[\"mse\"]=mean_squared_error(y_test,y_pred)\n",
    "d[\"mae\"]=mean_absolute_error(y_test,y_pred)\n",
    "d[\"rmse\"]=np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check r^2 and Adjusted r^2 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1={}\n",
    "r2=r2_score(y_test,y_pred)\n",
    "d1[\"r2\"]=r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nminusone=len(x_test)-1\n",
    "nminuspminus1=(len(x_test)-len(x.columns)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_r2= 1 - ((1 - r2) * (nminusone) / (nminuspminus1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1[\"adjusted_r2\"]=adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 To the Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
